{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Insurance Claim Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from tabulate import tabulate\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "We will begin by reading in and taking a quick look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════╤══════════════════════╤═══════╤═════════════════╤════════════════════╤════════════════╤══════════════╤═════════════════════╤═════════════════════════╤══════════════════╤═══════════════╤═══════════════╤═══════════════════════════╤══════════════════════╤═══════════════════╤════════════════════════╤═════════════════╤════════════════╤═════════════════╤══════════════════════════╤══════════════════╤═════════════════════╤═════════════════════════╤══════════════════╤═════════════════╤═════════════════════╤════════════════════════════╤═══════════════════════════════╤═══════════════════╤═══════════════════╤═════════════╤═══════════════════════════╤══════════════════════╤════════════════╤══════════════════╤═════════════════╤═════════════╤══════════════╤═════════════╤══════════════════╕\n",
      "│    │   months_as_customer │   age │   policy_number │ policy_bind_date   │ policy_state   │ policy_csl   │   policy_deductable │   policy_annual_premium │   umbrella_limit │   insured_zip │ insured_sex   │ insured_education_level   │ insured_occupation   │ insured_hobbies   │ insured_relationship   │   capital_gains │   capital_loss │ incident_date   │ incident_type            │ collision_type   │ incident_severity   │ authorities_contacted   │ incident_state   │ incident_city   │ incident_location   │   incident_hour_of_the_day │   number_of_vehicles_involved │ property_damage   │   bodily_injuries │   witnesses │ police_report_available   │   total_claim_amount │   injury_claim │   property_claim │   vehicle_claim │ auto_make   │ auto_model   │   auto_year │ fraud_reported   │\n",
      "╞════╪══════════════════════╪═══════╪═════════════════╪════════════════════╪════════════════╪══════════════╪═════════════════════╪═════════════════════════╪══════════════════╪═══════════════╪═══════════════╪═══════════════════════════╪══════════════════════╪═══════════════════╪════════════════════════╪═════════════════╪════════════════╪═════════════════╪══════════════════════════╪══════════════════╪═════════════════════╪═════════════════════════╪══════════════════╪═════════════════╪═════════════════════╪════════════════════════════╪═══════════════════════════════╪═══════════════════╪═══════════════════╪═════════════╪═══════════════════════════╪══════════════════════╪════════════════╪══════════════════╪═════════════════╪═════════════╪══════════════╪═════════════╪══════════════════╡\n",
      "│  0 │                  328 │    48 │          521585 │ 2014-10-17         │ OH             │ 250/500      │                1000 │                 1406.91 │                0 │        466132 │ MALE          │ MD                        │ craft-repair         │ sleeping          │ husband                │           53300 │              0 │ 2015-01-25      │ Single Vehicle Collision │ Side Collision   │ Major Damage        │ Police                  │ SC               │ Columbus        │ 9935 4th Drive      │                          5 │                             1 │ YES               │                 1 │           2 │ YES                       │                71610 │           6510 │            13020 │           52080 │ Saab        │ 92x          │        2004 │ Y                │\n",
      "├────┼──────────────────────┼───────┼─────────────────┼────────────────────┼────────────────┼──────────────┼─────────────────────┼─────────────────────────┼──────────────────┼───────────────┼───────────────┼───────────────────────────┼──────────────────────┼───────────────────┼────────────────────────┼─────────────────┼────────────────┼─────────────────┼──────────────────────────┼──────────────────┼─────────────────────┼─────────────────────────┼──────────────────┼─────────────────┼─────────────────────┼────────────────────────────┼───────────────────────────────┼───────────────────┼───────────────────┼─────────────┼───────────────────────────┼──────────────────────┼────────────────┼──────────────────┼─────────────────┼─────────────┼──────────────┼─────────────┼──────────────────┤\n",
      "│  1 │                  228 │    42 │          342868 │ 2006-06-27         │ IN             │ 250/500      │                2000 │                 1197.22 │          5000000 │        468176 │ MALE          │ MD                        │ machine-op-inspct    │ reading           │ other-relative         │               0 │              0 │ 2015-01-21      │ Vehicle Theft            │ ?                │ Minor Damage        │ Police                  │ VA               │ Riverwood       │ 6608 MLK Hwy        │                          8 │                             1 │ ?                 │                 0 │           0 │ ?                         │                 5070 │            780 │              780 │            3510 │ Mercedes    │ E400         │        2007 │ Y                │\n",
      "├────┼──────────────────────┼───────┼─────────────────┼────────────────────┼────────────────┼──────────────┼─────────────────────┼─────────────────────────┼──────────────────┼───────────────┼───────────────┼───────────────────────────┼──────────────────────┼───────────────────┼────────────────────────┼─────────────────┼────────────────┼─────────────────┼──────────────────────────┼──────────────────┼─────────────────────┼─────────────────────────┼──────────────────┼─────────────────┼─────────────────────┼────────────────────────────┼───────────────────────────────┼───────────────────┼───────────────────┼─────────────┼───────────────────────────┼──────────────────────┼────────────────┼──────────────────┼─────────────────┼─────────────┼──────────────┼─────────────┼──────────────────┤\n",
      "│  2 │                  134 │    29 │          687698 │ 2000-09-06         │ OH             │ 100/300      │                2000 │                 1413.14 │          5000000 │        430632 │ FEMALE        │ PhD                       │ sales                │ board-games       │ own-child              │           35100 │              0 │ 2015-02-22      │ Multi-vehicle Collision  │ Rear Collision   │ Minor Damage        │ Police                  │ NY               │ Columbus        │ 7121 Francis Lane   │                          7 │                             3 │ NO                │                 2 │           3 │ NO                        │                34650 │           7700 │             3850 │           23100 │ Dodge       │ RAM          │        2007 │ N                │\n",
      "├────┼──────────────────────┼───────┼─────────────────┼────────────────────┼────────────────┼──────────────┼─────────────────────┼─────────────────────────┼──────────────────┼───────────────┼───────────────┼───────────────────────────┼──────────────────────┼───────────────────┼────────────────────────┼─────────────────┼────────────────┼─────────────────┼──────────────────────────┼──────────────────┼─────────────────────┼─────────────────────────┼──────────────────┼─────────────────┼─────────────────────┼────────────────────────────┼───────────────────────────────┼───────────────────┼───────────────────┼─────────────┼───────────────────────────┼──────────────────────┼────────────────┼──────────────────┼─────────────────┼─────────────┼──────────────┼─────────────┼──────────────────┤\n",
      "│  3 │                  256 │    41 │          227811 │ 1990-05-25         │ IL             │ 250/500      │                2000 │                 1415.74 │          6000000 │        608117 │ FEMALE        │ PhD                       │ armed-forces         │ board-games       │ unmarried              │           48900 │         -62400 │ 2015-01-10      │ Single Vehicle Collision │ Front Collision  │ Major Damage        │ Police                  │ OH               │ Arlington       │ 6956 Maple Drive    │                          5 │                             1 │ ?                 │                 1 │           2 │ NO                        │                63400 │           6340 │             6340 │           50720 │ Chevrolet   │ Tahoe        │        2014 │ Y                │\n",
      "├────┼──────────────────────┼───────┼─────────────────┼────────────────────┼────────────────┼──────────────┼─────────────────────┼─────────────────────────┼──────────────────┼───────────────┼───────────────┼───────────────────────────┼──────────────────────┼───────────────────┼────────────────────────┼─────────────────┼────────────────┼─────────────────┼──────────────────────────┼──────────────────┼─────────────────────┼─────────────────────────┼──────────────────┼─────────────────┼─────────────────────┼────────────────────────────┼───────────────────────────────┼───────────────────┼───────────────────┼─────────────┼───────────────────────────┼──────────────────────┼────────────────┼──────────────────┼─────────────────┼─────────────┼──────────────┼─────────────┼──────────────────┤\n",
      "│  4 │                  228 │    44 │          367455 │ 2014-06-06         │ IL             │ 500/1000     │                1000 │                 1583.91 │          6000000 │        610706 │ MALE          │ Associate                 │ sales                │ board-games       │ unmarried              │           66000 │         -46000 │ 2015-02-17      │ Vehicle Theft            │ ?                │ Minor Damage        │ None                    │ NY               │ Arlington       │ 3041 3rd Ave        │                         20 │                             1 │ NO                │                 0 │           1 │ NO                        │                 6500 │           1300 │              650 │            4550 │ Accura      │ RSX          │        2009 │ N                │\n",
      "╘════╧══════════════════════╧═══════╧═════════════════╧════════════════════╧════════════════╧══════════════╧═════════════════════╧═════════════════════════╧══════════════════╧═══════════════╧═══════════════╧═══════════════════════════╧══════════════════════╧═══════════════════╧════════════════════════╧═════════════════╧════════════════╧═════════════════╧══════════════════════════╧══════════════════╧═════════════════════╧═════════════════════════╧══════════════════╧═════════════════╧═════════════════════╧════════════════════════════╧═══════════════════════════════╧═══════════════════╧═══════════════════╧═════════════╧═══════════════════════════╧══════════════════════╧════════════════╧══════════════════╧═════════════════╧═════════════╧══════════════╧═════════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv(os.getcwd() + '\\insurance_claims.csv')\n",
    "print(tabulate(raw_data.head(), headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the following columns contain entries with a \"?\" which denotes a missing value\n",
    "    <br />&nbsp;&nbsp;&nbsp;&nbsp;• *collision_type*\n",
    "    <br />&nbsp;&nbsp;&nbsp;&nbsp;• *property_damage*\n",
    "    <br />&nbsp;&nbsp;&nbsp;&nbsp;• *police_report_available*\n",
    "    <br />\n",
    "\n",
    "We will replace these entries with NANs.\n",
    "<br />\n",
    "Furthermore, we will convert the '*fraud_reported*' column, which is our target variable, to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.replace('?', np.nan, inplace = True)\n",
    "raw_data['fraud_reported'] = raw_data['fraud_reported'].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we identify the columns with missing values and their respective amount.\n",
    "<br />\n",
    "\n",
    "Looking below, these columns are:\n",
    "<br />&nbsp;• *collision_type*\n",
    "<br />&nbsp;• *property_damage*\n",
    "<br />&nbsp;• *police_report_available*\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collision_type             178\n",
       "property_damage            360\n",
       "police_report_available    343\n",
       "dtype: int64"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.isnull().sum()[raw_data.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we take a look at the *collision_type* column.\n",
    "<br />\n",
    "Below we determine that the corresponding *incident_type* for all missing values of *collision_type* are either **Vehicle Theft** or **Parked Car**.\n",
    "<br />\n",
    "Furthermore, *collision_type* is missing for all rows where the *incident_type* is either **Vehicle Theft** or **Parked Car**.\n",
    "<br />\n",
    "In both instances, the policy holder is not present to witness the damage done to their car.\n",
    "<br />\n",
    "And so, we replace all NAN values for this column with 'Unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries for incident_type where collision_type is missing: ['Vehicle Theft' 'Parked Car']\n",
      "Entries for collision_type where incident_type is in ['Vehicle Theft' 'Parked Car']: [nan]\n"
     ]
    }
   ],
   "source": [
    "incident_type_where_collision_type_missing = raw_data.loc[raw_data['collision_type'].isna()]['incident_type'].unique()\n",
    "print(\"Entries for incident_type where collision_type is missing: \" + str(incident_type_where_collision_type_missing))\n",
    "print(\"Entries for collision_type where incident_type is in \" + str(incident_type_where_collision_type_missing) + \": \" +\n",
    "        str(raw_data.loc[raw_data['incident_type'].isin(incident_type_where_collision_type_missing)]['collision_type'].unique()))\n",
    "raw_data['collision_type'].replace(np.nan, 'Unknown', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to the remaining columns that contain missing values: *property_damage* and *police_report_available*.<br />\n",
    "There doesn't seem to be a connection in the entries where *property_damage* or *police_report_available* data is missing.<br />\n",
    "One would assume that if property damage and a police report were present, it would be less likely to be a case of fraud.<br />\n",
    "However, these details simply being missing is not a good enough indicator of fraud.<br />\n",
    "These do not seem like values that we can impute with accuracy, so we will also change these missing values to 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['property_damage'].replace(np.nan, 'Unknown', inplace = True)\n",
    "raw_data['police_report_available'].replace(np.nan, 'Unknown', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating A Baseline Model\n",
    "In this section we will create and evaluate a baseline model. <br />\n",
    "Our baseline model will be a simple Decision Tree that is trained using only the numeric data from our dataset. <br />\n",
    "Below we see that the accuracy score of our baseline model is 64.4%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Accuracy: 64.4%\n"
     ]
    }
   ],
   "source": [
    "# define the list of columns containing non-numeric values\n",
    "non_numeric_cols = ['policy_csl', 'insured_sex', 'insured_education_level', 'insured_relationship', 'incident_type', 'collision_type', 'incident_severity', 'authorities_contacted',\n",
    "                        'property_damage', 'police_report_available', 'policy_bind_date', 'insured_zip', 'insured_hobbies', 'incident_date', 'incident_city', 'incident_location', 'auto_make', 'auto_model',\n",
    "                        'policy_state', 'insured_occupation', 'incident_state']\n",
    "\n",
    "# create a subset of our data, dropping the non-numeric and target columns and divide into a 75/25 split\n",
    "baseline_X = raw_data.copy()\n",
    "baseline_X.drop(non_numeric_cols, inplace=True, axis=1)\n",
    "baseline_X = baseline_X.drop('fraud_reported', axis=1)\n",
    "y = raw_data['fraud_reported']\n",
    "train_bl_X, val_bl_X, train_bl_y, val_bl_y = train_test_split(baseline_X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# the baseline model is defined, fit and the accuracy score is recorded to be referenced later\n",
    "baseline_model = DecisionTreeClassifier(random_state=0)\n",
    "baseline_model.fit(train_bl_X, train_bl_y)\n",
    "baseline_predictions = baseline_model.predict(val_bl_X)\n",
    "baseline_score = accuracy_score(val_bl_y, baseline_predictions)\n",
    "print('Baseline Model Accuracy: ' + str(round(baseline_score * 100, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Attempting to improve from our baseline model, we being by dividing the columns of interest into numeric and categorical columns. <br />\n",
    "Taking a closer look at our categorical columns below, we see that they each have a reasonable number of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy_csl: 3\n",
      "insured_sex: 2\n",
      "insured_education_level: 7\n",
      "insured_relationship: 6\n",
      "incident_type: 4\n",
      "collision_type: 4\n",
      "incident_severity: 4\n",
      "authorities_contacted: 5\n",
      "property_damage: 3\n",
      "police_report_available: 3\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = ['months_as_customer', 'age', 'policy_deductable', 'policy_annual_premium', 'umbrella_limit', 'capital_gains', 'capital_loss', 'incident_hour_of_the_day',\n",
    "                    'number_of_vehicles_involved', 'bodily_injuries', 'witnesses', 'total_claim_amount', 'injury_claim', 'property_claim', 'vehicle_claim']\n",
    "categorical_cols = ['policy_csl', 'insured_sex', 'insured_education_level', 'insured_relationship', 'incident_type', 'collision_type', 'incident_severity', 'authorities_contacted',\n",
    "                        'property_damage', 'police_report_available']\n",
    "\n",
    "# for each categorical column, output the column name and number of unique values\n",
    "for col in categorical_cols:\n",
    "    print(col + \": \" + str(len(raw_data[col].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the categorical columns are converted into indicator variables using *pd.get_dummies*. <br />\n",
    "We drop the first column to help reduce the extra columns created, thereby reducing the correlations created among dummy variables. <br />\n",
    "All of the relevant data is then combined into X, which is now a DataFrame containing solely numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════╤══════════════════════╤═══════╤═════════════════════╤═════════════════════════╤══════════════════╤═════════════════╤════════════════╤════════════════════════════╤═══════════════════════════════╤═══════════════════╤═════════════╤══════════════════════╤════════════════╤══════════════════╤═════════════════╤══════════════════════╤═══════════════════════╤════════════════════╤═══════════════════════════════════╤═══════════════════════════════════════╤══════════════════════════════╤══════════════════════════════╤═══════════════════════════════════╤═══════════════════════════════╤══════════════════════════════════════╤═══════════════════════════════════════╤══════════════════════════════════╤══════════════════════════════════╤═════════════════════════════╤════════════════════════════╤══════════════════════════════════════════╤═══════════════════════════════╤═════════════════════════════════╤═════════════════════════════════╤══════════════════════════╤══════════════════════════════════╤════════════════════════════════╤════════════════════════════════════╤══════════════════════════════╤══════════════════════════════╤═══════════════════════════════╤════════════════════════════════╤═══════════════════════════╤═══════════════════════╤═══════════════════════════════════╤═══════════════════════════════╕\n",
      "│    │   months_as_customer │   age │   policy_deductable │   policy_annual_premium │   umbrella_limit │   capital_gains │   capital_loss │   incident_hour_of_the_day │   number_of_vehicles_involved │   bodily_injuries │   witnesses │   total_claim_amount │   injury_claim │   property_claim │   vehicle_claim │   policy_csl_250/500 │   policy_csl_500/1000 │   insured_sex_MALE │   insured_education_level_College │   insured_education_level_High School │   insured_education_level_JD │   insured_education_level_MD │   insured_education_level_Masters │   insured_education_level_PhD │   insured_relationship_not-in-family │   insured_relationship_other-relative │   insured_relationship_own-child │   insured_relationship_unmarried │   insured_relationship_wife │   incident_type_Parked Car │   incident_type_Single Vehicle Collision │   incident_type_Vehicle Theft │   collision_type_Rear Collision │   collision_type_Side Collision │   collision_type_Unknown │   incident_severity_Minor Damage │   incident_severity_Total Loss │   incident_severity_Trivial Damage │   authorities_contacted_Fire │   authorities_contacted_None │   authorities_contacted_Other │   authorities_contacted_Police │   property_damage_Unknown │   property_damage_YES │   police_report_available_Unknown │   police_report_available_YES │\n",
      "╞════╪══════════════════════╪═══════╪═════════════════════╪═════════════════════════╪══════════════════╪═════════════════╪════════════════╪════════════════════════════╪═══════════════════════════════╪═══════════════════╪═════════════╪══════════════════════╪════════════════╪══════════════════╪═════════════════╪══════════════════════╪═══════════════════════╪════════════════════╪═══════════════════════════════════╪═══════════════════════════════════════╪══════════════════════════════╪══════════════════════════════╪═══════════════════════════════════╪═══════════════════════════════╪══════════════════════════════════════╪═══════════════════════════════════════╪══════════════════════════════════╪══════════════════════════════════╪═════════════════════════════╪════════════════════════════╪══════════════════════════════════════════╪═══════════════════════════════╪═════════════════════════════════╪═════════════════════════════════╪══════════════════════════╪══════════════════════════════════╪════════════════════════════════╪════════════════════════════════════╪══════════════════════════════╪══════════════════════════════╪═══════════════════════════════╪════════════════════════════════╪═══════════════════════════╪═══════════════════════╪═══════════════════════════════════╪═══════════════════════════════╡\n",
      "│  0 │                  328 │    48 │                1000 │                 1406.91 │            0     │           53300 │              0 │                          5 │                             1 │                 1 │           2 │                71610 │           6510 │            13020 │           52080 │                    1 │                     0 │                  1 │                                 0 │                                     0 │                            0 │                            1 │                                 0 │                             0 │                                    0 │                                     0 │                                0 │                                0 │                           0 │                          0 │                                        1 │                             0 │                               0 │                               1 │                        0 │                                0 │                              0 │                                  0 │                            0 │                            0 │                             0 │                              1 │                         0 │                     1 │                                 0 │                             1 │\n",
      "├────┼──────────────────────┼───────┼─────────────────────┼─────────────────────────┼──────────────────┼─────────────────┼────────────────┼────────────────────────────┼───────────────────────────────┼───────────────────┼─────────────┼──────────────────────┼────────────────┼──────────────────┼─────────────────┼──────────────────────┼───────────────────────┼────────────────────┼───────────────────────────────────┼───────────────────────────────────────┼──────────────────────────────┼──────────────────────────────┼───────────────────────────────────┼───────────────────────────────┼──────────────────────────────────────┼───────────────────────────────────────┼──────────────────────────────────┼──────────────────────────────────┼─────────────────────────────┼────────────────────────────┼──────────────────────────────────────────┼───────────────────────────────┼─────────────────────────────────┼─────────────────────────────────┼──────────────────────────┼──────────────────────────────────┼────────────────────────────────┼────────────────────────────────────┼──────────────────────────────┼──────────────────────────────┼───────────────────────────────┼────────────────────────────────┼───────────────────────────┼───────────────────────┼───────────────────────────────────┼───────────────────────────────┤\n",
      "│  1 │                  228 │    42 │                2000 │                 1197.22 │            5e+06 │               0 │              0 │                          8 │                             1 │                 0 │           0 │                 5070 │            780 │              780 │            3510 │                    1 │                     0 │                  1 │                                 0 │                                     0 │                            0 │                            1 │                                 0 │                             0 │                                    0 │                                     1 │                                0 │                                0 │                           0 │                          0 │                                        0 │                             1 │                               0 │                               0 │                        1 │                                1 │                              0 │                                  0 │                            0 │                            0 │                             0 │                              1 │                         1 │                     0 │                                 1 │                             0 │\n",
      "├────┼──────────────────────┼───────┼─────────────────────┼─────────────────────────┼──────────────────┼─────────────────┼────────────────┼────────────────────────────┼───────────────────────────────┼───────────────────┼─────────────┼──────────────────────┼────────────────┼──────────────────┼─────────────────┼──────────────────────┼───────────────────────┼────────────────────┼───────────────────────────────────┼───────────────────────────────────────┼──────────────────────────────┼──────────────────────────────┼───────────────────────────────────┼───────────────────────────────┼──────────────────────────────────────┼───────────────────────────────────────┼──────────────────────────────────┼──────────────────────────────────┼─────────────────────────────┼────────────────────────────┼──────────────────────────────────────────┼───────────────────────────────┼─────────────────────────────────┼─────────────────────────────────┼──────────────────────────┼──────────────────────────────────┼────────────────────────────────┼────────────────────────────────────┼──────────────────────────────┼──────────────────────────────┼───────────────────────────────┼────────────────────────────────┼───────────────────────────┼───────────────────────┼───────────────────────────────────┼───────────────────────────────┤\n",
      "│  2 │                  134 │    29 │                2000 │                 1413.14 │            5e+06 │           35100 │              0 │                          7 │                             3 │                 2 │           3 │                34650 │           7700 │             3850 │           23100 │                    0 │                     0 │                  0 │                                 0 │                                     0 │                            0 │                            0 │                                 0 │                             1 │                                    0 │                                     0 │                                1 │                                0 │                           0 │                          0 │                                        0 │                             0 │                               1 │                               0 │                        0 │                                1 │                              0 │                                  0 │                            0 │                            0 │                             0 │                              1 │                         0 │                     0 │                                 0 │                             0 │\n",
      "├────┼──────────────────────┼───────┼─────────────────────┼─────────────────────────┼──────────────────┼─────────────────┼────────────────┼────────────────────────────┼───────────────────────────────┼───────────────────┼─────────────┼──────────────────────┼────────────────┼──────────────────┼─────────────────┼──────────────────────┼───────────────────────┼────────────────────┼───────────────────────────────────┼───────────────────────────────────────┼──────────────────────────────┼──────────────────────────────┼───────────────────────────────────┼───────────────────────────────┼──────────────────────────────────────┼───────────────────────────────────────┼──────────────────────────────────┼──────────────────────────────────┼─────────────────────────────┼────────────────────────────┼──────────────────────────────────────────┼───────────────────────────────┼─────────────────────────────────┼─────────────────────────────────┼──────────────────────────┼──────────────────────────────────┼────────────────────────────────┼────────────────────────────────────┼──────────────────────────────┼──────────────────────────────┼───────────────────────────────┼────────────────────────────────┼───────────────────────────┼───────────────────────┼───────────────────────────────────┼───────────────────────────────┤\n",
      "│  3 │                  256 │    41 │                2000 │                 1415.74 │            6e+06 │           48900 │         -62400 │                          5 │                             1 │                 1 │           2 │                63400 │           6340 │             6340 │           50720 │                    1 │                     0 │                  0 │                                 0 │                                     0 │                            0 │                            0 │                                 0 │                             1 │                                    0 │                                     0 │                                0 │                                1 │                           0 │                          0 │                                        1 │                             0 │                               0 │                               0 │                        0 │                                0 │                              0 │                                  0 │                            0 │                            0 │                             0 │                              1 │                         1 │                     0 │                                 0 │                             0 │\n",
      "├────┼──────────────────────┼───────┼─────────────────────┼─────────────────────────┼──────────────────┼─────────────────┼────────────────┼────────────────────────────┼───────────────────────────────┼───────────────────┼─────────────┼──────────────────────┼────────────────┼──────────────────┼─────────────────┼──────────────────────┼───────────────────────┼────────────────────┼───────────────────────────────────┼───────────────────────────────────────┼──────────────────────────────┼──────────────────────────────┼───────────────────────────────────┼───────────────────────────────┼──────────────────────────────────────┼───────────────────────────────────────┼──────────────────────────────────┼──────────────────────────────────┼─────────────────────────────┼────────────────────────────┼──────────────────────────────────────────┼───────────────────────────────┼─────────────────────────────────┼─────────────────────────────────┼──────────────────────────┼──────────────────────────────────┼────────────────────────────────┼────────────────────────────────────┼──────────────────────────────┼──────────────────────────────┼───────────────────────────────┼────────────────────────────────┼───────────────────────────┼───────────────────────┼───────────────────────────────────┼───────────────────────────────┤\n",
      "│  4 │                  228 │    44 │                1000 │                 1583.91 │            6e+06 │           66000 │         -46000 │                         20 │                             1 │                 0 │           1 │                 6500 │           1300 │              650 │            4550 │                    0 │                     1 │                  1 │                                 0 │                                     0 │                            0 │                            0 │                                 0 │                             0 │                                    0 │                                     0 │                                0 │                                1 │                           0 │                          0 │                                        0 │                             1 │                               0 │                               0 │                        1 │                                1 │                              0 │                                  0 │                            0 │                            1 │                             0 │                              0 │                         0 │                     0 │                                 0 │                             0 │\n",
      "╘════╧══════════════════════╧═══════╧═════════════════════╧═════════════════════════╧══════════════════╧═════════════════╧════════════════╧════════════════════════════╧═══════════════════════════════╧═══════════════════╧═════════════╧══════════════════════╧════════════════╧══════════════════╧═════════════════╧══════════════════════╧═══════════════════════╧════════════════════╧═══════════════════════════════════╧═══════════════════════════════════════╧══════════════════════════════╧══════════════════════════════╧═══════════════════════════════════╧═══════════════════════════════╧══════════════════════════════════════╧═══════════════════════════════════════╧══════════════════════════════════╧══════════════════════════════════╧═════════════════════════════╧════════════════════════════╧══════════════════════════════════════════╧═══════════════════════════════╧═════════════════════════════════╧═════════════════════════════════╧══════════════════════════╧══════════════════════════════════╧════════════════════════════════╧════════════════════════════════════╧══════════════════════════════╧══════════════════════════════╧═══════════════════════════════╧════════════════════════════════╧═══════════════════════════╧═══════════════════════╧═══════════════════════════════════╧═══════════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "categorical_df = pd.get_dummies(raw_data[categorical_cols], drop_first=True)\n",
    "numerical_df = raw_data[numerical_cols]\n",
    "X = pd.concat([numerical_df, categorical_df], axis=1)\n",
    "print(tabulate(X.head(), headers=\"keys\", tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of feature engineering, we will focus on reducing any prevalent multicollinearity. <br />\n",
    "We will use VIF scores to determine the variables with significant multicollinearity, which will have a score of 10 or greater. <br />\n",
    "\n",
    "Taking a look at the scores below, we can deduce the following:\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *age* is highly correlated to *months_as_customer*\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *total_claim_amount*, *vehicle_claim*, *property_claim*, *injury_claim* are all highly correlated as *total_claim_amount* is a sum of the rest\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *collision_type_unknown* is highly correlated to *incident_type_Vehicle Theft* and *incident_type_Parked Car* because the collison type is always unknown in those two incident types\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *incident_type_Single Vehicle Collision* is highly correlated to *number_of_vehicles_involved*\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *policy_annual_premium* and *vehicle_claim* are highly correlated to other variables because the are determined depending on the other variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\Anaconda3\\envs\\AutoInsFraud\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   feature         VIF\n",
      "30  incident_type_Single Vehicle Collision   14.564231\n",
      "3                    policy_annual_premium   26.270979\n",
      "0                       months_as_customer   26.583771\n",
      "8              number_of_vehicles_involved   35.794012\n",
      "1                                      age  117.837187\n",
      "11                      total_claim_amount         inf\n",
      "12                            injury_claim         inf\n",
      "13                          property_claim         inf\n",
      "14                           vehicle_claim         inf\n",
      "29                incident_type_Parked Car         inf\n",
      "31             incident_type_Vehicle Theft         inf\n",
      "34                  collision_type_Unknown         inf\n"
     ]
    }
   ],
   "source": [
    "def get_VIF(df):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = df.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(len(df.columns))]\n",
    "    return vif_data\n",
    "\n",
    "vif_scores = get_VIF(X)\n",
    "print(vif_scores[vif_scores[\"VIF\"] >= 10].sort_values('VIF'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above deductions, the below columns are dropped:\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *age*\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *total_claim_amount*\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *collision_type_unknown*\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *incident_type_Single Vehicle Collision*\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *policy_annual_premium*\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *vehicle_claim*\n",
    "<br />\n",
    "<br />\n",
    "Looking at the VIF scores again, there no longer remains a column with a score of at least 10. <br />\n",
    "And so we have successfully reduced any prevalent multicollinearity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [feature, VIF]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "X.drop(['age', 'total_claim_amount', 'collision_type_Unknown', 'incident_type_Single Vehicle Collision', 'policy_annual_premium', 'vehicle_claim'], inplace=True, axis=1)\n",
    "vif_scores = get_VIF(X)\n",
    "print(vif_scores[vif_scores[\"VIF\"] >= 10].sort_values('VIF'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "In this section, the base model for each machine learning algorithm and its associated parameters for tuning are initialized. <br />\n",
    "We also define the number of folds for cross validation to be 5.<br />\n",
    "This means that each time a model is trained, it is trained 5 times; each of which is on a shuffling 4/5ths of the data and then tested on the remaining 1/5th. <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the models and their associated parameters for hypertuning\n",
    "dt_model = DecisionTreeClassifier(random_state=0)\n",
    "rf_model = RandomForestClassifier(random_state=0)\n",
    "gb_model = GradientBoostingClassifier(random_state=0)\n",
    "xgb_model = XGBClassifier(random_state=0)\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "dt_params = {'max_depth': [3, 5, 10, 15, 20],\n",
    "             'min_samples_leaf': [5, 10, 20, 50, 100]}\n",
    "rf_params = {'n_estimators': [10, 25, 50, 75, 100],\n",
    "             'max_depth': [3, 5, 10, 15, 20],\n",
    "             'min_samples_leaf': [5, 10, 20, 50, 100]}\n",
    "gb_params = {'learning_rate': [0.1, 0.25, 0.5, 1, 5],\n",
    "             'n_estimators': [10, 25, 50, 75, 100],\n",
    "             'max_depth': [3, 5, 10, 15, 20],\n",
    "             'min_samples_leaf': [5, 10, 20, 50, 100]}\n",
    "xgb_params = {'learning_rate': [0.1, 0.25, 0.5, 1, 5],\n",
    "             'n_estimators': [10, 25, 50, 75, 100],\n",
    "             'max_depth': [3, 5, 10, 15, 20]}\n",
    "knn_params = {'n_neighbors': [10, 20, 30, 40, 50],\n",
    "              'leaf_size': [10, 20, 30, 40, 50]}\n",
    "\n",
    "all_models = {'Decision Tree': [dt_model, dt_params], 'Random Forest': [rf_model, rf_params], 'Gradient Boost': [gb_model, gb_params],\n",
    "               'XG Boost': [xgb_model, xgb_params], 'K Nearest Neighbours': [knn_model, knn_params]}\n",
    "\n",
    "# define the folds to be used for cross validation\n",
    "k_folds = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Via Hypertuning\n",
    "In this section, each model is trained using each combination of their parameters. <br />\n",
    "For each algorithm, its highest scoring model (including its parameters) is stored, along with its score. <br />\n",
    "\n",
    "Note: This training process can take a few minutes, as there are 925 models that are trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree Model...\n",
      "Training Random Forest Model...\n",
      "Training Gradient Boost Model...\n",
      "Training XG Boost Model...\n",
      "Training K Nearest Neighbours Model...\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "def evaluate_grid_search_cv(estimator, params, folds, X, y):\n",
    "    grid_search = GridSearchCV(estimator=estimator, param_grid=params, cv=folds, n_jobs=-1, scoring='accuracy')\n",
    "    grid_search.fit(X, y)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_score = grid_search.best_score_\n",
    "    return [best_model, best_score]\n",
    "\n",
    "for key, items in all_models.items():\n",
    "    print(\"Training \" + key + \" Model...\")\n",
    "    [model, params] = items[0], items[1]\n",
    "    [best_model, best_score] = evaluate_grid_search_cv(model, params, k_folds, X, y)\n",
    "    items.extend([str(best_model), best_score, best_model])\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "Below is a table containing each algorithm with its best performing model and its accuracy obtained. <br />\n",
    "We see that our best scoring model is a Decision Tree with max_depth=3 and min_samples_leaf=10, with a score of 81.1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════════════════╤══════════════════════════════════════════════════════════════════════════════════╤═════════════════════════╕\n",
      "│                      │ Best Model Label                                                                 │   Best Average Accuracy │\n",
      "╞══════════════════════╪══════════════════════════════════════════════════════════════════════════════════╪═════════════════════════╡\n",
      "│ Decision Tree        │ DecisionTreeClassifier(max_depth=3, min_samples_leaf=10, random_state=0)         │                   0.811 │\n",
      "├──────────────────────┼──────────────────────────────────────────────────────────────────────────────────┼─────────────────────────┤\n",
      "│ XG Boost             │ XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,                  │                   0.811 │\n",
      "│                      │               colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,       │                         │\n",
      "│                      │               early_stopping_rounds=None, enable_categorical=False,              │                         │\n",
      "│                      │               eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',     │                         │\n",
      "│                      │               importance_type=None, interaction_constraints='',                  │                         │\n",
      "│                      │               learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,               │                         │\n",
      "│                      │               max_delta_step=0, max_depth=3, max_leaves=0, min_child_weight=1,   │                         │\n",
      "│                      │               missing=nan, monotone_constraints='()', n_estimators=10, n_jobs=0, │                         │\n",
      "│                      │               num_parallel_tree=1, predictor='auto', random_state=0,             │                         │\n",
      "│                      │               reg_alpha=0, reg_lambda=1, ...)                                    │                         │\n",
      "├──────────────────────┼──────────────────────────────────────────────────────────────────────────────────┼─────────────────────────┤\n",
      "│ Gradient Boost       │ GradientBoostingClassifier(max_depth=15, min_samples_leaf=50, random_state=0)    │                   0.797 │\n",
      "├──────────────────────┼──────────────────────────────────────────────────────────────────────────────────┼─────────────────────────┤\n",
      "│ Random Forest        │ RandomForestClassifier(max_depth=20, min_samples_leaf=5, n_estimators=10,        │                   0.771 │\n",
      "│                      │                        random_state=0)                                           │                         │\n",
      "├──────────────────────┼──────────────────────────────────────────────────────────────────────────────────┼─────────────────────────┤\n",
      "│ K Nearest Neighbours │ KNeighborsClassifier(leaf_size=10, n_neighbors=20)                               │                   0.754 │\n",
      "├──────────────────────┼──────────────────────────────────────────────────────────────────────────────────┼─────────────────────────┤\n",
      "│ Baseline Model       │ DecisionTreeClassifier(random_state=0)                                           │                   0.644 │\n",
      "╘══════════════════════╧══════════════════════════════════════════════════════════════════════════════════╧═════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "best_score_df = pd.DataFrame.from_dict(data=all_models, orient='index', columns=['Model', 'Parameters', 'Best Model Label', 'Best Average Accuracy', 'Best Model'])\n",
    "best_score_df.loc[\"Baseline Model\"] = [str(baseline_model), None, str(baseline_model), baseline_score, baseline_model]\n",
    "print(tabulate(best_score_df[['Best Model Label', 'Best Average Accuracy']].sort_values(by='Best Average Accuracy', ascending=False), headers='keys', tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating The Dollar Amount Paid To Fraudulent Claims\n",
    "In this final section, we take a look at the dollar amount paid in all claims, actual fraud claims and predicted fraud claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total claim amount: $52761940\n",
      "Total claim amount of actual fraudulent claims: $14894620, 28.23% of total claim amount\n",
      "Total claim amount of predicted fraudulent claims: $17682540, 33.51% of total claim amount\n",
      "\n",
      "Total difference between actual and predicted amounts: $2787920 or 5.28%\n"
     ]
    }
   ],
   "source": [
    "# use the optimal model to predict whether each claim is fraudulent and append the predictions to our original data\n",
    "optimal_row = best_score_df['Best Average Accuracy'].idxmax()\n",
    "optimal_model = best_score_df.loc[optimal_row]['Best Model']\n",
    "optimal_preds = optimal_model.predict(X)\n",
    "raw_data['predicted_fraud'] = optimal_preds\n",
    "\n",
    "# store the total amount of actual and predicted fraudulent claims\n",
    "total_claim_amount = raw_data['total_claim_amount'].sum()\n",
    "actual_fraud_amount = raw_data[raw_data['fraud_reported'] == 1]['total_claim_amount'].sum()\n",
    "predicted_fraud_amount = raw_data[raw_data['predicted_fraud'] == 1]['total_claim_amount'].sum()\n",
    "actual_fraud_percentage = round((actual_fraud_amount/total_claim_amount) * 100, 2)\n",
    "predicted_fraud_percentage = round((predicted_fraud_amount/total_claim_amount) * 100, 2)\n",
    "\n",
    "# display the amounts paid in all claims, actual fraud claims and predicted fraud claims\n",
    "print(\"Total claim amount: $\" + str(raw_data['total_claim_amount'].sum()))\n",
    "print(\"Total claim amount of actual fraudulent claims: $\" + str(actual_fraud_amount) + \", \" + str(actual_fraud_percentage) + \"% of total claim amount\")\n",
    "print(\"Total claim amount of predicted fraudulent claims: $\" + str(predicted_fraud_amount) + \", \" + str(predicted_fraud_percentage) + \"% of total claim amount\")\n",
    "print(\"\\nTotal difference between actual and predicted amounts: $\" + str(abs(actual_fraud_amount - predicted_fraud_amount)) +\n",
    "        \" or \" + str(round(abs(actual_fraud_percentage - predicted_fraud_percentage),2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping up, we see that although our optimal model had an accuracy of just 81.1%, it over estimates the dollar amount in fraudulent claims by $2787920, which is 5.28% more of the total claim amount than the actual amount. <br />\n",
    "\n",
    "Not bad!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('AutoInsFraud')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7bf7b960292e5b026972bd6ec60a2f1123a2a36330106063654a1f123679985"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
