{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Insurance Claim Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "We will begin by reading in and taking a quick look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2007</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990-05-25</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>2014</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>Accura</td>\n",
       "      <td>RSX</td>\n",
       "      <td>2009</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                 328   48         521585       2014-10-17           OH   \n",
       "1                 228   42         342868       2006-06-27           IN   \n",
       "2                 134   29         687698       2000-09-06           OH   \n",
       "3                 256   41         227811       1990-05-25           IL   \n",
       "4                 228   44         367455       2014-06-06           IL   \n",
       "\n",
       "  policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0    250/500               1000                1406.91               0   \n",
       "1    250/500               2000                1197.22         5000000   \n",
       "2    100/300               2000                1413.14         5000000   \n",
       "3    250/500               2000                1415.74         6000000   \n",
       "4   500/1000               1000                1583.91         6000000   \n",
       "\n",
       "   insured_zip  ... witnesses police_report_available total_claim_amount  \\\n",
       "0       466132  ...         2                     YES              71610   \n",
       "1       468176  ...         0                       ?               5070   \n",
       "2       430632  ...         3                      NO              34650   \n",
       "3       608117  ...         2                      NO              63400   \n",
       "4       610706  ...         1                      NO               6500   \n",
       "\n",
       "  injury_claim property_claim  vehicle_claim  auto_make auto_model auto_year  \\\n",
       "0         6510          13020          52080       Saab        92x      2004   \n",
       "1          780            780           3510   Mercedes       E400      2007   \n",
       "2         7700           3850          23100      Dodge        RAM      2007   \n",
       "3         6340           6340          50720  Chevrolet      Tahoe      2014   \n",
       "4         1300            650           4550     Accura        RSX      2009   \n",
       "\n",
       "  fraud_reported  \n",
       "0              Y  \n",
       "1              Y  \n",
       "2              N  \n",
       "3              Y  \n",
       "4              N  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(os.getcwd() + '\\insurance_claims.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the following columns contain entries with a \"?\" which denotes a missing value\n",
    "    <br />&nbsp;&nbsp;&nbsp;&nbsp;• *collision_type*\n",
    "    <br />&nbsp;&nbsp;&nbsp;&nbsp;• *property_damage*\n",
    "    <br />&nbsp;&nbsp;&nbsp;&nbsp;• *police_report_available*\n",
    "    <br />\n",
    "\n",
    "We will replace these entries with NANs.\n",
    "<br />\n",
    "Furthermore, we will convert the '*fraud_reported*' column, which is our target variable, to binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.replace('?', np.nan, inplace = True)\n",
    "raw_data['fraud_reported'] = raw_data['fraud_reported'].map({'Y': 1, 'N': 0})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we identify the columns with missing values and their respective amount.\n",
    "<br />\n",
    "\n",
    "Looking below, these columns are:\n",
    "<br />&nbsp;• *collision_type*\n",
    "<br />&nbsp;• *property_damage*\n",
    "<br />&nbsp;• *police_report_available*\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collision_type             178\n",
       "property_damage            360\n",
       "police_report_available    343\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.isnull().sum()[raw_data.isnull().sum() > 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we take a look at the *collision_type* column.\n",
    "<br />\n",
    "Below we determine that the corresponding *incident_type* for all missing values of *collision_type* are either **Vehicle Theft** or **Parked Car**.\n",
    "<br />\n",
    "Furthermore, *collision_type* is missing for all rows where the *incident_type* is either **Vehicle Theft** or **Parked Car**.\n",
    "<br />\n",
    "In both instances, the policy holder is not present to witness the damage done to their car.\n",
    "<br />\n",
    "And so, we replace all NAN values for this column with 'Unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries for incident_type where collision_type is missing: ['Vehicle Theft' 'Parked Car']\n",
      "Entries for collision_type where incident_type is in ['Vehicle Theft' 'Parked Car']: [nan]\n"
     ]
    }
   ],
   "source": [
    "incident_type_where_collision_type_missing = raw_data.loc[raw_data['collision_type'].isna()]['incident_type'].unique()\n",
    "print(\"Entries for incident_type where collision_type is missing: \" + str(incident_type_where_collision_type_missing))\n",
    "print(\"Entries for collision_type where incident_type is in \" + str(incident_type_where_collision_type_missing) + \": \" +\n",
    "        str(raw_data.loc[raw_data['incident_type'].isin(incident_type_where_collision_type_missing)]['collision_type'].unique()))\n",
    "raw_data['collision_type'].replace(np.nan, 'Unknown', inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to the remaining columns that contain missing values: *property_damage* and *police_report_available*.<br />\n",
    "There doesn't seem to be a connection in the entries where *property_damage* or *police_report_available* data is missing.<br />\n",
    "One would assume that if property damage and a police report were present, it would be less likely to be a case of fraud.<br />\n",
    "However, these details simply being missing is not a good enough indicator of fraud.<br />\n",
    "These do not seem like values that we can impute with accuracy, so we will also change these missing values to 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data['property_damage'].replace(np.nan, 'Unknown', inplace = True)\n",
    "raw_data['police_report_available'].replace(np.nan, 'Unknown', inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating A Baseline Model\n",
    "In this section we will create and evaluate a baseline model. <br />\n",
    "Our baseline model will be a simple Decision Tree that is trained using only the numeric data from our dataset. <br />\n",
    "Below we see that the accuracy score of our baseline model is 64.4%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Accuracy: 64.4%\n"
     ]
    }
   ],
   "source": [
    "# define the list of columns containing non-numeric values\n",
    "non_numeric_cols = ['policy_csl', 'insured_sex', 'insured_education_level', 'insured_relationship', 'incident_type', 'collision_type',\n",
    "                        'incident_severity', 'authorities_contacted', 'property_damage', 'police_report_available', 'policy_bind_date',\n",
    "                        'insured_zip', 'insured_hobbies', 'incident_date', 'incident_city', 'incident_location', 'auto_make', 'auto_model',\n",
    "                        'policy_state', 'insured_occupation', 'incident_state']\n",
    "\n",
    "# create a subset of our data, dropping the non-numeric and target columns and divide into a 75/25 split\n",
    "baseline_X = raw_data.copy()\n",
    "baseline_X.drop(non_numeric_cols, inplace=True, axis=1)\n",
    "baseline_X = baseline_X.drop('fraud_reported', axis=1)\n",
    "y = raw_data['fraud_reported']\n",
    "train_bl_X, val_bl_X, train_bl_y, val_bl_y = train_test_split(baseline_X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# the baseline model is defined, fit and the accuracy score is recorded to be referenced later\n",
    "baseline_model = DecisionTreeClassifier(random_state=0)\n",
    "baseline_model.fit(train_bl_X, train_bl_y)\n",
    "baseline_predictions = baseline_model.predict(val_bl_X)\n",
    "baseline_score = accuracy_score(val_bl_y, baseline_predictions)\n",
    "print('Baseline Model Accuracy: ' + str(round(baseline_score * 100, 2)) + \"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Attempting to improve from our baseline model, we begin by sorting the columns of interest into numeric and categorical columns. <br />\n",
    "Taking a closer look at our categorical columns below, we see that they each have a reasonable number of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy_csl: 3\n",
      "insured_sex: 2\n",
      "insured_education_level: 7\n",
      "insured_relationship: 6\n",
      "incident_type: 4\n",
      "collision_type: 4\n",
      "incident_severity: 4\n",
      "authorities_contacted: 5\n",
      "property_damage: 3\n",
      "police_report_available: 3\n"
     ]
    }
   ],
   "source": [
    "numerical_cols = ['months_as_customer', 'age', 'policy_deductable', 'policy_annual_premium', 'umbrella_limit', 'capital_gains', 'capital_loss',\n",
    "                    'incident_hour_of_the_day', 'number_of_vehicles_involved', 'bodily_injuries', 'witnesses', 'total_claim_amount', 'injury_claim',\n",
    "                    'property_claim', 'vehicle_claim']\n",
    "categorical_cols = ['policy_csl', 'insured_sex', 'insured_education_level', 'insured_relationship', 'incident_type', 'collision_type',\n",
    "                        'incident_severity', 'authorities_contacted', 'property_damage', 'police_report_available']\n",
    "\n",
    "# for each categorical column, output the column name and number of unique values\n",
    "for col in categorical_cols:\n",
    "    print(col + \": \" + str(len(raw_data[col].unique())))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the categorical columns are converted into indicator variables using *pd.get_dummies*. <br />\n",
    "We drop the first column to help reduce the extra columns created, thereby reducing the correlations created among dummy variables. <br />\n",
    "All of the relevant data is then combined into X, which is now a DataFrame containing solely numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>capital_gains</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>incident_hour_of_the_day</th>\n",
       "      <th>number_of_vehicles_involved</th>\n",
       "      <th>bodily_injuries</th>\n",
       "      <th>...</th>\n",
       "      <th>incident_severity_Total Loss</th>\n",
       "      <th>incident_severity_Trivial Damage</th>\n",
       "      <th>authorities_contacted_Fire</th>\n",
       "      <th>authorities_contacted_None</th>\n",
       "      <th>authorities_contacted_Other</th>\n",
       "      <th>authorities_contacted_Police</th>\n",
       "      <th>property_damage_Unknown</th>\n",
       "      <th>property_damage_YES</th>\n",
       "      <th>police_report_available_Unknown</th>\n",
       "      <th>police_report_available_YES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>53300</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>35100</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>48900</td>\n",
       "      <td>-62400</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>66000</td>\n",
       "      <td>-46000</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_deductable  policy_annual_premium  \\\n",
       "0                 328   48               1000                1406.91   \n",
       "1                 228   42               2000                1197.22   \n",
       "2                 134   29               2000                1413.14   \n",
       "3                 256   41               2000                1415.74   \n",
       "4                 228   44               1000                1583.91   \n",
       "\n",
       "   umbrella_limit  capital_gains  capital_loss  incident_hour_of_the_day  \\\n",
       "0               0          53300             0                         5   \n",
       "1         5000000              0             0                         8   \n",
       "2         5000000          35100             0                         7   \n",
       "3         6000000          48900        -62400                         5   \n",
       "4         6000000          66000        -46000                        20   \n",
       "\n",
       "   number_of_vehicles_involved  bodily_injuries  ...  \\\n",
       "0                            1                1  ...   \n",
       "1                            1                0  ...   \n",
       "2                            3                2  ...   \n",
       "3                            1                1  ...   \n",
       "4                            1                0  ...   \n",
       "\n",
       "   incident_severity_Total Loss  incident_severity_Trivial Damage  \\\n",
       "0                             0                                 0   \n",
       "1                             0                                 0   \n",
       "2                             0                                 0   \n",
       "3                             0                                 0   \n",
       "4                             0                                 0   \n",
       "\n",
       "   authorities_contacted_Fire  authorities_contacted_None  \\\n",
       "0                           0                           0   \n",
       "1                           0                           0   \n",
       "2                           0                           0   \n",
       "3                           0                           0   \n",
       "4                           0                           1   \n",
       "\n",
       "   authorities_contacted_Other  authorities_contacted_Police  \\\n",
       "0                            0                             1   \n",
       "1                            0                             1   \n",
       "2                            0                             1   \n",
       "3                            0                             1   \n",
       "4                            0                             0   \n",
       "\n",
       "   property_damage_Unknown  property_damage_YES  \\\n",
       "0                        0                    1   \n",
       "1                        1                    0   \n",
       "2                        0                    0   \n",
       "3                        1                    0   \n",
       "4                        0                    0   \n",
       "\n",
       "   police_report_available_Unknown  police_report_available_YES  \n",
       "0                                0                            1  \n",
       "1                                1                            0  \n",
       "2                                0                            0  \n",
       "3                                0                            0  \n",
       "4                                0                            0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_df = pd.get_dummies(raw_data[categorical_cols], drop_first=True)\n",
    "numerical_df = raw_data[numerical_cols]\n",
    "X = pd.concat([numerical_df, categorical_df], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of feature engineering, we will focus on reducing any prevalent multicollinearity. <br />\n",
    "We will use VIF scores to determine the variables with significant multicollinearity, which will have a score of 10 or greater. <br />\n",
    "\n",
    "Taking a look at the scores below, we can deduce the following:\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *age* is highly correlated to *months_as_customer*\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *total_claim_amount*, *vehicle_claim*, *property_claim*, *injury_claim* are all highly correlated as *total_claim_amount* is a sum of the rest\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *collision_type_unknown* is highly correlated to *incident_type_Vehicle Theft* and *incident_type_Parked Car* because the collison type is always unknown in those two incident types\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *incident_type_Single Vehicle Collision* is highly correlated to *number_of_vehicles_involved*\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *policy_annual_premium* and *vehicle_claim* are highly correlated to other variables because the are determined depending on the other variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\Anaconda3\\envs\\AutoInsFraud\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   feature         VIF\n",
      "30  incident_type_Single Vehicle Collision   14.564231\n",
      "3                    policy_annual_premium   26.270979\n",
      "0                       months_as_customer   26.583771\n",
      "8              number_of_vehicles_involved   35.794012\n",
      "1                                      age  117.837187\n",
      "11                      total_claim_amount         inf\n",
      "12                            injury_claim         inf\n",
      "13                          property_claim         inf\n",
      "14                           vehicle_claim         inf\n",
      "29                incident_type_Parked Car         inf\n",
      "31             incident_type_Vehicle Theft         inf\n",
      "34                  collision_type_Unknown         inf\n"
     ]
    }
   ],
   "source": [
    "def get_VIF(df):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = df.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(len(df.columns))]\n",
    "    return vif_data\n",
    "\n",
    "vif_scores = get_VIF(X)\n",
    "print(vif_scores[vif_scores[\"VIF\"] >= 10].sort_values('VIF'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above deductions, the below columns are dropped:\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *age*\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *total_claim_amount*\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *collision_type_unknown*\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *incident_type_Single Vehicle Collision*\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *policy_annual_premium*\n",
    "<br />&nbsp;&nbsp;&nbsp;&nbsp;• *vehicle_claim*\n",
    "<br />\n",
    "<br />\n",
    "Looking at the VIF scores again, there no longer remains a column with a score of at least 10. <br />\n",
    "And so we have successfully reduced any prevalent multicollinearity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [feature, VIF]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "X.drop(['age', 'total_claim_amount', 'collision_type_Unknown', 'incident_type_Single Vehicle Collision', 'policy_annual_premium', 'vehicle_claim'],\n",
    "            inplace=True, axis=1)\n",
    "vif_scores = get_VIF(X)\n",
    "print(vif_scores[vif_scores[\"VIF\"] >= 10].sort_values('VIF'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "In this section, the base model for each machine learning algorithm and its associated parameters for tuning are initialized. <br />\n",
    "We also define the number of folds for cross validation to be 5.<br />\n",
    "This means that each time a model is trained, it is trained 5 times; each of which is on a shuffling 4/5ths of the data and then tested on the remaining 1/5th. <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the models and their associated parameters for hypertuning\n",
    "dt_model = DecisionTreeClassifier(random_state=0)\n",
    "rf_model = RandomForestClassifier(random_state=0)\n",
    "gb_model = GradientBoostingClassifier(random_state=0)\n",
    "xgb_model = XGBClassifier(random_state=0)\n",
    "knn_model = KNeighborsClassifier()\n",
    "\n",
    "dt_params = {'max_depth': [3, 5, 10, 15, 20],\n",
    "             'min_samples_leaf': [5, 10, 20, 50, 100]}\n",
    "rf_params = {'n_estimators': [10, 25, 50, 75, 100],\n",
    "             'max_depth': [3, 5, 10, 15, 20],\n",
    "             'min_samples_leaf': [5, 10, 20, 50, 100]}\n",
    "gb_params = {'learning_rate': [0.1, 0.25, 0.5, 1, 5],\n",
    "             'n_estimators': [10, 25, 50, 75, 100],\n",
    "             'max_depth': [3, 5, 10, 15, 20],\n",
    "             'min_samples_leaf': [5, 10, 20, 50, 100]}\n",
    "xgb_params = {'learning_rate': [0.1, 0.25, 0.5, 1, 5],\n",
    "             'n_estimators': [10, 25, 50, 75, 100],\n",
    "             'max_depth': [3, 5, 10, 15, 20]}\n",
    "knn_params = {'n_neighbors': [10, 20, 30, 40, 50],\n",
    "              'leaf_size': [10, 20, 30, 40, 50]}\n",
    "\n",
    "all_models = {'Decision Tree': [dt_model, dt_params], 'Random Forest': [rf_model, rf_params], 'Gradient Boost': [gb_model, gb_params],\n",
    "               'XG Boost': [xgb_model, xgb_params], 'K Nearest Neighbours': [knn_model, knn_params]}\n",
    "\n",
    "# define the folds to be used for cross validation\n",
    "k_folds = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Via Hypertuning\n",
    "In this section, each model is trained using each combination of their parameters. <br />\n",
    "For each algorithm, its highest scoring model (including its parameters) is stored, along with its score. <br />\n",
    "\n",
    "Note: This training process can take a few minutes, as there are 925 models that are trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Decision Tree Model...\n",
      "Training Random Forest Model...\n",
      "Training Gradient Boost Model...\n",
      "Training XG Boost Model...\n",
      "Training K Nearest Neighbours Model...\n",
      "Training Complete!\n"
     ]
    }
   ],
   "source": [
    "def evaluate_grid_search_cv(estimator, params, folds, X, y):\n",
    "    grid_search = GridSearchCV(estimator=estimator, param_grid=params, cv=folds, n_jobs=-1, scoring='accuracy')\n",
    "    grid_search.fit(X, y)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_score = grid_search.best_score_\n",
    "    return [best_model, best_score]\n",
    "\n",
    "for key, items in all_models.items():\n",
    "    print(\"Training \" + key + \" Model...\")\n",
    "    [model, params] = items[0], items[1]\n",
    "    [best_model, best_score] = evaluate_grid_search_cv(model, params, k_folds, X, y)\n",
    "    items.extend([str(best_model), best_score, best_model])\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "Below is a table containing each algorithm with its best performing model and its accuracy obtained. <br />\n",
    "We see that our best scoring model is a Decision Tree with max_depth=3 and min_samples_leaf=10, with a score of 81.1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                       Best Model Label  \\\n",
      "Decision Tree         DecisionTreeClassifier(max_depth=3, min_sample...   \n",
      "XG Boost              XGBClassifier(base_score=0.5, booster='gbtree'...   \n",
      "Gradient Boost        GradientBoostingClassifier(max_depth=15, min_s...   \n",
      "Random Forest         RandomForestClassifier(max_depth=20, min_sampl...   \n",
      "K Nearest Neighbours  KNeighborsClassifier(leaf_size=10, n_neighbors...   \n",
      "Baseline Model                   DecisionTreeClassifier(random_state=0)   \n",
      "\n",
      "                      Best Average Accuracy  \n",
      "Decision Tree                         0.811  \n",
      "XG Boost                              0.811  \n",
      "Gradient Boost                        0.797  \n",
      "Random Forest                         0.771  \n",
      "K Nearest Neighbours                  0.754  \n",
      "Baseline Model                        0.644  \n"
     ]
    }
   ],
   "source": [
    "best_score_df = pd.DataFrame.from_dict(data=all_models, orient='index', \n",
    "                                        columns=['Model', 'Parameters', 'Best Model Label', 'Best Average Accuracy', 'Best Model'])\n",
    "best_score_df.loc[\"Baseline Model\"] = [str(baseline_model), None, str(baseline_model), baseline_score, baseline_model]\n",
    "#print(tabulate(best_score_df[['Best Model Label', 'Best Average Accuracy']].sort_values(by='Best Average Accuracy', ascending=False),\n",
    "#               headers='keys', tablefmt='fancy_grid'))\n",
    "print(best_score_df[['Best Model Label', 'Best Average Accuracy']].sort_values(by='Best Average Accuracy', ascending=False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating The Dollar Amount Paid To Fraudulent Claims\n",
    "In this final section, we take a look at the dollar amount paid in all claims, actual fraud claims and predicted fraud claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total claim amount: $52761940\n",
      "Total claim amount of actual fraudulent claims: $14894620, 28.23% of total claim amount\n",
      "Total claim amount of predicted fraudulent claims: $17682540, 33.51% of total claim amount\n",
      "Total difference between actual and predicted amounts: $2787920 or 5.28%\n"
     ]
    }
   ],
   "source": [
    "# use the optimal model to predict whether each claim is fraudulent and append the predictions to our original data\n",
    "optimal_row = best_score_df['Best Average Accuracy'].idxmax()\n",
    "optimal_model = best_score_df.loc[optimal_row]['Best Model']\n",
    "optimal_preds = optimal_model.predict(X)\n",
    "raw_data['predicted_fraud'] = optimal_preds\n",
    "\n",
    "# store the total amount of actual and predicted fraudulent claims\n",
    "total_claim_amount = raw_data['total_claim_amount'].sum()\n",
    "actual_fraud_amount = raw_data[raw_data['fraud_reported'] == 1]['total_claim_amount'].sum()\n",
    "predicted_fraud_amount = raw_data[raw_data['predicted_fraud'] == 1]['total_claim_amount'].sum()\n",
    "actual_fraud_percentage = round((actual_fraud_amount/total_claim_amount) * 100, 2)\n",
    "predicted_fraud_percentage = round((predicted_fraud_amount/total_claim_amount) * 100, 2)\n",
    "\n",
    "# display the amounts paid in all claims, actual fraud claims and predicted fraud claims\n",
    "# and the difference between actual and predicted\n",
    "print(\"Total claim amount: $\" + str(raw_data['total_claim_amount'].sum()))\n",
    "print(\"Total claim amount of actual fraudulent claims: $\" + str(actual_fraud_amount) +\n",
    "        \", \" + str(actual_fraud_percentage) + \"% of total claim amount\")\n",
    "print(\"Total claim amount of predicted fraudulent claims: $\" + str(predicted_fraud_amount) +\n",
    "        \", \" + str(predicted_fraud_percentage) + \"% of total claim amount\")\n",
    "print(\"Total difference between actual and predicted amounts: $\" + str(abs(actual_fraud_amount - predicted_fraud_amount)) +\n",
    "        \" or \" + str(round(abs(actual_fraud_percentage - predicted_fraud_percentage),2)) + \"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping up, we see that although our optimal model had an accuracy of just 81.1%, it over estimates the dollar amount in fraudulent claims by $2787920, which is 5.28% more of the total claim amount than the actual amount. <br />\n",
    "\n",
    "Not bad!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('AutoInsFraud')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7bf7b960292e5b026972bd6ec60a2f1123a2a36330106063654a1f123679985"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
